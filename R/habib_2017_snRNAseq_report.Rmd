---
title: "Habib 2017 snRNAseq Report"
author:
  - name: "Emir Turkes [et2628@cumc.columbia.edu]"
  - name: "Columbia University"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: "../habib-2017-snRNAseq.bib"
biblio-style: apalike
link-citations: true
output:
  html_document:
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit:
  (function(inputFile, encoding) {
    rmarkdown::render(
      inputFile, encoding = encoding, output_file = "../results/habib-2017-snRNAseq-report.html")})
---

```{r, include = FALSE}
#    This file is part of habib-2017-snRNAseq.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

knitr::opts_chunk$set(fig.width = 8.5, fig.height = 7)
```

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This is a broad initial analysis that prepares and characterizes the data for use in other projects.*

The background for this data is as follows:

- dbGaP Accession: [phs000424](https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000424.v7.p2).
- Part of [GTEx](https://gtexportal.org/home/) and originally published in @habib_massively_2017.
- Archived frozen adult human post-mortem tissue from 5 donors.
- 3 prefrontal cortex samples, 4 hippocampal samples.
- 14,963 nuclei, 31,930 genes.

This analysis was performed in R except where noted.
The source code and instructions for rerunning the analysis can be found at [github.com/eturkes/habib-2017-snRNAseq](https://github.com/eturkes/habib-2017-snRNAseq).

# Final Results

**Read just the following sub-sections (1.1-1.2) for the final results of the analysis and a brief summary of the methods.**

```{r, include = FALSE}
packages <- c(
  "conflicted", "BiocFileCache", "data.table", "DT", "SingleCellExperiment", "biomaRt", "S4Vectors",
  "dplyr", "SummarizedExperiment", "DropletUtils", "scater", "scran", "ggrepel", "BiocSingular",
  "ggplot2", "svd", "Rtsne", "knitr", "kableExtra", "Seurat")
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))

options(stringsAsFactors = FALSE)

results_dir <- file.path(getwd(), "..", "results")

# ggplot2 function providing custom aesthetics and automatic placement of categorical labels.
# For continuous data, a colorbar is implemented.
dim_red_plot <- function(data, x, y, col, type) {
  gg <- ggplot(data, aes_string(x = x, y = y, color = col)) +
    geom_point(alpha = 0.35, stroke = 0.05, shape = 21, aes_string(fill = col)) +
    theme_classic() +
    theme(
      legend.position = "right", plot.title = element_text(hjust = 0.5),
      legend.title = element_blank()) +
    guides(color = guide_legend(override.aes = list(alpha = 1)))
    if (type == "cat") {
      gg <- gg + geom_label_repel(data = label_df2, aes(label = label), show.legend = FALSE)
    } else if (type == "cont") {
      gg <- ggplot(data, aes_string(x = x, y = y)) +
        geom_point(alpha = 0.35, stroke = 0.05, aes_string(color = col)) +
        theme_classic() +
        theme(
          legend.position = "right", plot.title = element_text(hjust = 0.5),
          legend.title = element_blank()) +
        scale_colour_gradient(low = "blue", high = "red")}
  gg}

sce_orig <- readRDS(file.path(results_dir, "data", "sce_orig.rds"))
sce <- readRDS(file.path(results_dir, "data", "sce.rds"))
sce_hvg <- readRDS(file.path(results_dir, "data", "sce_hvg.rds"))
seurat <- readRDS(file.path(results_dir, "data", "seurat.rds"))
```

## SCE Object of Original Data

The dataset in @habib_massively_2017 includes transcript counts, cluster labels, and tSNE coordinates.
However, in order to transform the data to the main figures seen in the paper, some additional QC was required.
The protocol described in @habib_massively_2017 was followed where possible and included the addition of gene annotations, the removal of low-quality nuclei, the removal of lowly-expressed genes, and normalization.
The data was also transformed into an SCE (SingleCellExperiment) object as well as a Seurat object, both of which facilitate easy interface with popular software packages.
These objects, along with an SCE object subsetted to the top HVGs (highly variable genes, about 6,000), and an object without QC, are included in the `results/data/` directory of this project.

```{r, message = FALSE}
sce_orig
sce
sce_hvg
seurat
```

## Reproduction and Replication {.tabset}

The below tabs display reproductions and replications of the results in @habib_massively_2017.
Note the presence of several "Unlabeled" clusters that are included in the dataset but removed from the final figures in the publication.
Overall, it can be seen that our reproduction and replication of the results in @habib_massively_2017 agree well with the original publication.

```{r, include = FALSE}
# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    paste0("habib_tsne", 1:2), paste0("hvg_svd_tsne", 1:2), "habib_cluster_name",
    "km_18_clusters_name", "seurat_clusters_name")])
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)
gg_df$km_18_clusters_name <- factor(gg_df$km_18_clusters_name)
gg_df$seurat_clusters_name <- factor(gg_df$seurat_clusters_name)
rm(sce_org)
```

### Habib Clusters Habib tSNE

```{r, echo = FALSE, message = FALSE}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name), label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2",col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters Habib tSNE")
```

### KM 18 Clusters Habib tSNE

```{r, echo = FALSE, message = FALSE}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_18_clusters_name = levels(gg_df$km_18_clusters_name),
  label = levels(gg_df$km_18_clusters_name))
label_df2 <- gg_df %>%
  group_by(km_18_clusters_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "km_18_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("KM 18 Clusters Habib tSNE")
```

### Seurat Clusters Habib tSNE

```{r, echo = FALSE, message = FALSE}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_clusters_name = levels(gg_df$seurat_clusters_name),
  label = levels(gg_df$seurat_clusters_name))
label_df2 <- gg_df %>%
  group_by(seurat_clusters_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "seurat_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Seurat Clusters Habib tSNE")
```

### Seurat Clusters Seurat tSNE

```{r, echo = FALSE, message = FALSE}
DimPlot(object = seurat, reduction = "tsne", label = TRUE)
```

### KM 18 Clusters HVG SVD tSNE

```{r, echo = FALSE, message = FALSE}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_18_clusters_name = levels(gg_df$km_18_clusters_name),
  label = levels(gg_df$km_18_clusters_name))
label_df2 <- gg_df %>%
  group_by(km_18_clusters_name) %>%
  summarize(hvg_svd_tsne1 = median(hvg_svd_tsne1), hvg_svd_tsne2 = median(hvg_svd_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2", col = "km_18_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("KM 18 Clusters HVG SVD tSNE")
```

### Habib Clusters HVG SVD tSNE

```{r, echo = FALSE, message = FALSE}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name), label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(hvg_svd_tsne1 = median(hvg_svd_tsne1), hvg_svd_tsne2 = median(hvg_svd_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2", col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters HVG SVD tSNE")
```

# ~~~ Breakdown of Methods ~~~ {-}

**Sections from here to the end break down the methods used and are optional to read.**

We start by loading in any required packages and setting some global variables.

```{r}
packages <- c(
  "conflicted", "BiocFileCache", "data.table", "DT", "SingleCellExperiment", "biomaRt", "S4Vectors",
  "dplyr", "SummarizedExperiment", "DropletUtils", "scater", "scran", "ggrepel", "BiocSingular",
  "ggplot2", "svd", "Rtsne", "knitr", "kableExtra", "Seurat")
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))

options(stringsAsFactors = FALSE)

data_str <- "GTEx_droncseq_hip_pcf"
data_dir <- file.path(getwd(), "..", "data")
assets_dir <- file.path(getwd(), "..", "assets")
results_dir <- file.path(getwd(), "..", "results")

# Create a cache for storing the objects of long-running computations.
if (!dir.exists(file.path(assets_dir, "cache"))) {
  dir.create(file.path(assets_dir, "cache"))}

# ggplot2 function providing custom aesthetics and automatic placement of categorical labels.
# For continuous data, a colorbar is implemented.
dim_red_plot <- function(data, x, y, col, type) {
  gg <- ggplot(data, aes_string(x = x, y = y, color = col)) +
    geom_point(alpha = 0.35, stroke = 0.05, shape = 21, aes_string(fill = col)) +
    theme_classic() +
    theme(
      legend.position = "right", plot.title = element_text(hjust = 0.5),
      legend.title = element_blank()) +
    guides(color = guide_legend(override.aes = list(alpha = 1)))
    if (type == "cat") {
      gg <- gg + geom_label_repel(data = label_df2, aes(label = label), show.legend = FALSE)
    } else if (type == "cont") {
      gg <- ggplot(data, aes_string(x = x, y = y)) +
        geom_point(alpha = 0.35, stroke = 0.05, aes_string(color = col)) +
        theme_classic() +
        theme(
          legend.position = "right", plot.title = element_text(hjust = 0.5),
          legend.title = element_blank()) +
        scale_colour_gradient(low = "blue", high = "red")}
  gg}
```

# Original Data {.tabset}

This section provides a brief look at the raw data before manipulation.

```{r}
bfc <- BiocFileCache(data_dir, ask = FALSE)
data <- bfcrpath(bfc, file.path(
  "https://storage.googleapis.com/gtex_additional_datasets/single_cell_data",
  paste0(data_str, ".tar")))
untar(data, exdir = tempdir())
rm(bfc)
```

## Counts

```{r}
counts <- fread(
  file.path(tempdir(), data_str, paste0(data_str, ".umi_counts.txt.gz")), data.table = FALSE)
datatable(counts[1:5, 1:3])
```

## Clusters

```{r}
# The original clusters file, GTEx_droncseq_hip_pcf.clusters.txt, has several inconsistencies.
# Specifically in clusters 15-18, which do not match those in the original publication.
# Therefore we use Supplementary Table 7 (nmeth.4407-S10.xlsx), which does not have those issues.
# However, because cluster 11 is incorrectly named in this table, we must correct that.
# Also, as this file contained non-standard formatting, minimal manual editing was done for use in R.
clust <- fread(file.path(assets_dir, "nmeth.4407-S10-edited.txt"), data.table = FALSE)
datatable(clust[1:5, ])
```

## tSNE

```{r}
tsne <- fread(file.path(tempdir(), data_str, paste0(data_str, ".tsne.txt.gz")), data.table = FALSE)
datatable(tsne[1:5, ])
```

# Preliminary Cleaning

Here we do any data wrangling neccessary to transform the data into more convenient formats for downstream analysis.

## Counts

```{r}
rownames(counts) <- counts[ , 1]
counts <- as.matrix(counts[ , -1])
cell_id_stem <- sapply(colnames(counts), function(xx) strsplit(xx, "_")[[1]][1], USE.NAMES = FALSE)
col_dat <- data.frame(sample = colnames(counts), cell_id_stem = cell_id_stem, check.names = FALSE)
datatable(counts[1:5, 1:3])

# Convert to dgCMatrix after datatable, as they are incompatible.
counts <- Matrix::Matrix(counts, sparse = TRUE)
```

## Clusters

```{r}
# Fix mislabeled cluster name and give unique names for unclassified clusters.
for (i in seq_len(nrow(clust))) {
  if (clust[i, 4] == 11) {
    clust[i, 5] <- "ODC2"
  } else if (clust[i, 4] == 16) {
    clust[i, 5] <- "Unlabeled1"
  } else if (clust[i, 4] == 17) {
    clust[i, 5] <- "Unlabeled2"
  } else if (clust[i, 4] == 18) {
    clust[i, 5] <- "Unlabeled3"}}

clust <- clust[ , -c(2:3)]
names(clust) <- c("sample", "habib_cluster", "habib_cluster_name")
clust$habib_cluster <- as.factor(clust$habib_cluster)
clust <- clust[match(col_dat$sample, clust$sample), ]
rownames(clust) <- NULL
datatable(clust[1:5, ])
```

## tSNE

```{r}
names(tsne) = c("sample", paste0("habib_tsne", 1:2))
datatable(tsne[1:5, ])
```

## SingleCellExperiment

The data is now sufficiently prepared to form a SingleCellExperiment (SCE) object.

```{r}
col_dat <- cbind(col_dat, clust[ , names(clust) != "sample"], tsne[ , names(tsne) != "sample"])
sce <- SingleCellExperiment(assays = list(counts = counts), colData = col_dat)
rm(counts, clust, tsne, col_dat)
sce
```

## Gene Annotations

In order to use standard gene symbols, which are often useful for downstream analysis, we add annotations based on the hg19 reference gnome, the same used in @habib_massively_2017.

```{r}
attributes <- c(
  "hgnc_symbol", "ensembl_gene_id", "external_gene_name", "chromosome_name", "start_position",
  "end_position", "strand", "description", "percentage_gene_gc_content", "gene_biotype")
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "gene_anno.rds")
if (file.exists(rds)) {
  gene_anno <- readRDS(rds)
} else {
  mart <- useEnsembl(biomart = "ensembl", GRCh = 37, dataset = "hsapiens_gene_ensembl")
  gene_anno <- getBM(
    attributes = attributes, filters = "external_gene_name", values = rownames(sce), mart = mart)
  rm(mart)
  saveRDS(gene_anno, rds)}
```

Before merging them into the SCE object, the annotation must be cleaned by removing genes not in the RNAseq dataset, irrelevant annotations, duplicate genes, and genes that are not annotated.

```{r}
# Remove genes not in the RNAseq dataset.
remove_genes <- which(!gene_anno$external_gene_name %in% rownames(sce))
gene_anno <- gene_anno[-remove_genes, ]

# Remove annotations to scaffolds, assembly patches, and alternative loci.
chromosomes <- c(1:22, "X", "Y", "MT")
gene_anno <- gene_anno[which(gene_anno$chromosome_name %in% chromosomes), ]

# Remove duplicates.
dup <- table(gene_anno$external_gene_name)
dup <- sort(dup[dup > 1], decreasing = TRUE)
dup <- which(gene_anno$external_gene_name %in% names(dup))
gene_anno2 <- gene_anno[dup, ]
gene_anno2 <- gene_anno2[which(gene_anno2$hgnc_symbol == gene_anno2$external_gene_name), ]
gene_anno2 <- distinct(gene_anno2, external_gene_name, .keep_all = TRUE)
gene_anno <- rbind(gene_anno[-dup, ], gene_anno2)

# Remove missing.
keep_genes <- match(gene_anno$external_gene_name, rownames(sce))
sce <- sce[keep_genes, ]

rowData(sce) <- gene_anno
names(rowData(sce))[names(rowData(sce)) == "strand"] <- "strand_n" # Conflicts with other packages.
rm(gene_anno, gene_anno2)
names(rowData(sce))
```

# QC

These sections assess and correct issues and irregularities in the dataset.
A number of standard QC steps that would normally be performed here were already carried out in @habib_massively_2017.
These steps are indicated and we simply double-check that they were performed on the dataset and carry them out if not.

## Empty Droplets

Empty droplets are typically identified as those that have no gene counts or only a small number of them (typically less than 100 to 200, resulting from the capture of ambient RNA).
@habib_massively_2017 describes this as having been done through the following:

> Nuclei with less than 200 detected genes and less than 10,000 usable reads were filtered out.

Furthermore, the paper states that 19,550 nuclei were extracted, but a subset of 14,963 of them were used for analysis.
This subset is identical to the nuclei counts in the imported dataset.

```{r}
dim(sce)
```

We cannot check for the removal of reads at this point but we can verify that all nuclei have at least 200 detected genes.
A straightforward way to do so is by using the `barcodeRanks` function of `DropletUtils`.

```{r}
bc_rank <- barcodeRanks(counts(sce))
uniq <- !duplicated(bc_rank$rank)
par(mar = c(5, 4, 2, 1), bty = "n")
plot(
  bc_rank$rank[uniq], bc_rank$total[uniq], log = "xy", xlab = "Rank",
  ylab = "Total Gene Count", cex = 0.5, cex.lab = 1.2)
```

We see from the lower limit of the plot that there is indeed a cutoff at 200 genes.
In a situation where this cutoff was not applied, we might apply it using the `emptyDrops` function from `scater`, which should provide a more robust approximation of empty droplets.

## Low Quality Nuclei

As we already have the number of nuclei used in @habib_massively_2017, we remove no further and only generate metrics to assess the effects of additional QC.
We start by investigating low library and feature sizes, as it is unclear whether the data was filtered on that basis.
Furthermore, we assess the proportion of ribosomal/mitochrondrial gene expression in nuclei, which has little to no mention in the publication.
While mitochrondrial genes are straightforward to extract from their HGNC gene symbol, an annotation set for ribosomal genes had to first be downloaded from HGNC, where they are then loaded from the `assets` directory.

```{r}
ribo_genes <- read.table(file.path(assets_dir, "ribo-genes.txt"), sep = "\t", header = TRUE)
is_mito <- which(rowData(sce)$chromosome_name == "MT")
is_ribo <- which(rowData(sce)$external_gene_name %in% ribo_genes$Approved.Symbol)
sce <- calculateQCMetrics(sce, feature_controls = list(mito = is_mito, ribo = is_ribo))
rm(ribo_genes, bc_rank)

par(mfrow = c(2, 2), mar = c(5, 4, 1, 1), bty = "n")
hist(
  sce$total_counts, xlab = "log10(Library Sizes)", main = "",
  breaks = 20, col = "grey80", ylab = "Number of Nuclei")
hist(
  log10(sce$total_features_by_counts), xlab = "log10(Number of Expressed Genes)", main = "",
  breaks = 20, col = "grey80", ylab = "Number of Nuclei")
hist(
  sce$pct_counts_ribo, xlab = "Ribosomal Proportion Percentage", ylab = "Number of Nuclei",
  breaks = 40, main = "", col = "grey80")
hist(
  sce$pct_counts_mito, xlab = "Mitochondrial Proportion Percentage", ylab = "Number of Nuclei",
  breaks = 80, main = "", col = "grey80")
par(mfrow = c(2, 2), mar = c(5, 4, 1, 1), bty = "n")
smoothScatter(
  log10(sce$total_counts), log10(sce$total_features_by_counts),
  xlab = "log10(Library Sizes)", ylab = "log10(Num. Expressed Genes)")
smoothScatter(
  log10(sce$total_counts), sce$pct_counts_ribo,
  xlab = "log10(Library Sizes)", ylab = "Ribosomal Proportion %")
smoothScatter(
  log10(sce$total_counts), sce$pct_counts_mito,
  xlab = "log10(Library Sizes)", ylab = "Mitochondrial Proportion %")
smoothScatter(
  sce$pct_counts_ribo,sce$pct_counts_mito, xlab = "Ribosomal Proportion %",
  ylab = "Mitochondrial Proportion %")
```

We look at the results if we were to remove outliers on the basis of these metrics.

```{r}
libsize_drop <- isOutlier(sce$total_counts, nmads = 3, type = "lower", log = TRUE)
feature_drop <- isOutlier(sce$total_features_by_counts, nmads = 3, type = "lower", log = TRUE)
mito_drop <- isOutlier(sce$pct_counts_mito, nmads = 3, type = "higher")
ribo_drop <- isOutlier(sce$pct_counts_ribo, nmads = 3, type = "higher")
keep <- !(libsize_drop | feature_drop | mito_drop | ribo_drop)
datatable(data.table(
  "By Library Size" = sum(libsize_drop), "By Feature" = sum(feature_drop),
  "By Mitochondrial" = sum(mito_drop), "By Ribosomal" = sum(ribo_drop),
  Remaining = sum(keep)))
```

We assume that filtering from library and feature size had already taken place, but not from ribosomal/mitochrondrial gene expression, important considerations for downstream analysis.

## Lowly Expressed Genes

Removal of lowly expressed genes has significant effects on downstream analysis, particularly for differential expression, as shown in @soneson_bias_2018.
The methods section of @habib_massively_2017 suggests that this had already been done:

> A gene is considered detected in a cell if it has at least two unique UMIs (transcripts) associated with it.
For each analysis, genes were removed that were detected in less than 10 nuclei.

However, we see that this is not the case our current dataset, either because it had not yet been applied or was applied before nuclei removal.

```{r}
head(rowData(sce)$n_cells_by_counts[order(rowData(sce)$n_cells_by_counts)])
```

It can be seen that the presence of these genes creates a distinctly negative skew.

```{r, fig.height = 6}
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Nuclei + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Nuclei + 1)")
```

Therefore, we remove genes in the manner specified in @habib_massively_2017.
As this step is destructive and irreversible, we first save a copy of the SCE object thus far for analyses in other projects that will use the complete data.

```{r}
saveRDS(sce, file.path(results_dir, "data", "sce_orig.rds"))
detected_genes <- rowSums(counts(sce) >= 2)
sce <- sce[which(detected_genes >= 10), ]
head(rowData(sce)$n_cells_by_counts[order(rowData(sce)$n_cells_by_counts)])
dim(sce)
```

We see a robust improvement in normality.

```{r, fig.height = 6}
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Nuclei + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Nuclei + 1)")
```

We then display some additional summary statistics.
Apparent is the disproportionately high expression of encoding lncRNAs MALAT1 and MEG3, both of which are known to have higher expression in nuclei, as noted in @habib_massively_2017.

```{r}
plotHighestExprs(sce, exprs_values = "counts")
plotExprsFreqVsMean(sce)
```

## Normalization

We use `computeSumFactors` from the `scran` package to perform normalization.
This function uses a linear deconvolution system to account for expected variation across different cell/nuclei types/sizes [@l_lun_pooling_2016], producing "size factor" values that indicate the extent to which a cell/nucleus should be scaled.
We also perform a rough clustering of our nuclei, which improves accuracy on highly heterogenous sets.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "quickCluster.rds")
if (file.exists(rds)) {
  quickCluster <- readRDS(rds)
} else {
  quickCluster <- quickCluster(sce, use.ranks = FALSE, min.mean = 0.1, BSPARAM = IrlbaParam())
  saveRDS(quickCluster, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "size_factors.rds")
if (file.exists(rds)) {
  size_factors <- readRDS(rds)
} else {
  size_factors <- computeSumFactors(sce, cluster = quickCluster, min.mean = 0.1)
  saveRDS(size_factors, rds)}
```

In an experiment where most systematic differences between nuclei are driven by capture efficiency and sequencing depth, we should see a correlation between size factors and library size.

```{r}
sce <- size_factors
rm(size_factors)
par(mfrow = c(1, 2), mar = c(5, 4, 2, 1), bty = "n")
smoothScatter(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts", ylab = "Size Factors")
plot(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts",
  ylab = "Size Factors", cex = 0.3, pch = 20, col = rgb(0.1, 0.2, 0.7, 0.3))
abline(h = 0.05)
```

The plots are well correlated, confirming the source of bias.
We therefore add normalized expression data to our SCE object using the calculated size factors.

```{r}
sce <- normalize(sce)
sce
```

# Dimensionality Reduction

Before creating our own clusters, we initially explore the data using various dimensionality reduction techniques, aided by the cluster labels provided in @habib_massively_2017.

## PCA

### denoisePCA

We start by applying `denoisePCA` from the `scran` package, which automatically selects PCs by modeling technical noise.

```{r}
new_trend <- makeTechTrend(x = sce)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "denoise_pca.rds")
if (file.exists(rds)) {
  denoise_pca <- readRDS(rds)
} else {
  denoise_pca <- denoisePCA(sce, technical = new_trend, BSPARAM = IrlbaParam())
  saveRDS(denoise_pca, rds)}
```

```{r}
sce <- denoise_pca
add_df <- data.frame(reducedDim(sce, "PCA"))
names(add_df) <- paste0("denoise_pc", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), denoise_pc1 = add_df$denoise_pc1, denoise_pc2 = add_df$denoise_pc2)

# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    "sample", "cell_id_stem", paste0("habib_tsne", 1:2),
    "log10_total_features_by_counts", "habib_cluster", "habib_cluster_name")],
  add_df[1:2])
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)
```

We use the first 34 PCs, chosen by visually identifying the dropoff in variance explained.

```{r}
par(mfrow = c(1, 1))
plot(
  log10(attr(reducedDim(sce), "percentVar")), xlab = "PC",
  ylab = "log10(Proportion of Variance Explained)", pch = 20,
  cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = 34, lty = 2, col = "red")
```

We take a closer look at the first four components and their ability to explain the cluster labels defined in @habib_massively_2017.

```{r}
plotPCA(sce, ncomponents = 4, colour_by = "habib_cluster_name") +
  ggtitle("Habib Clusters denoisePCA") + theme(legend.title = element_blank())
```

### SVD PCA

As an alternative, we can also calculate a truncated SVD (singular value decomposition) from which PCs can be extracted from it.
This approach was found to have high accuracy in a preprint review of PCA methods for scRNAseq [@tsuyuzaki_benchmarking_2019].

```{r}
edat <- t(as.matrix(logcounts(sce)))
edat <- scale(edat)
```

We set the desired eigentriples to the number of components selected after inspecting the `denoisePCA` results.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "ppk.rds")
if (file.exists(rds)) {
  ppk <- readRDS(rds)
} else {
  ppk <- propack.svd(edat, neig = 34)
  saveRDS(ppk, rds)}
```

```{r}
svd_pca <- t(ppk$d * t(ppk$u))
add_df <- data.frame(svd_pca)
names(add_df) <- paste0("svd_pc", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), svd_pc1 = add_df$svd_pc1, svd_pc2 = add_df$svd_pc2)
gg_df <- data.frame(gg_df, add_df[1:2])

dim_red_plot(
  data = gg_df, x = "svd_pc1", y = "svd_pc2", col = "habib_cluster_name", type = "other") +
  xlab("PC1") + ylab("PC2") + ggtitle("Habib Clusters SVD PCA")
```

## tSNE

We plot the tSNE coordinates provided in @habib_massively_2017 as well create new ones off of the PCs just created.

### Habib

It should be noted that the tSNE coordinates provided were generated using HVGs, not all genes in the set.

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name),
  label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2",
  col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters Habib tSNE")
dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "cell_id_stem", type = "other") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Sample Distribution Habib tSNE")
dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("log10(Total Features) Habib tSNE")
```

### denoisePCA tSNE

We first try using the first 34 PCs from the `denoisePCA` function.
The perplexity value is set to 100, as was used in @habib_massively_2017.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "denoise_tsne.rds")
if (file.exists(rds)) {
  tsne <- readRDS(rds)
} else {
  tsne <- runTSNE(sce, use_dimred = "PCA", n_dimred = 34, perplexity = 100, rand_seed = 1)
  saveRDS(tsne, rds)}
```

```{r}
sce <- tsne
add_df <- data.frame(reducedDim(sce, "TSNE"))
names(add_df) <- paste0("denoise_tsne", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), denoise_tsne1 = add_df$denoise_tsne1, denoise_tsne2 = add_df$denoise_tsne2)
gg_df <- data.frame(gg_df, add_df)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(denoise_tsne1 = median(denoise_tsne1), denoise_tsne2 = median(denoise_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "denoise_tsne1", y = "denoise_tsne2",
  col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters denoisePCA tSNE")
```

These PCs appear to drive a strong batch effect from certain hippocampal samples.

```{r}
dim_red_plot(
  data = gg_df, x = "denoise_tsne1", y = "denoise_tsne2",
  col = "cell_id_stem", type = "other") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Sample Distribution denoisePCA tSNE")
dim_red_plot(
  data = gg_df, x = "denoise_tsne1", y = "denoise_tsne2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("log10(Total Features) denoisePCA tSNE")
```

### SVD PCA tSNE

Next using the SVD PCs.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "svd_tsne.rds")
if (file.exists(rds)) {
  tsne <- readRDS(rds)
} else {
  set.seed(1)
  tsne <- Rtsne(svd_pca, pca = FALSE, perplexity = 100)
  saveRDS(tsne, rds)}
```

```{r}
reducedDims(sce) <- SimpleList(PCA = svd_pca, TSNE = tsne$Y)
add_df <- data.frame(reducedDim(sce, "TSNE"))
names(add_df) <- paste0("svd_tsne", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), svd_tsne1 = add_df$svd_tsne1, svd_tsne2 = add_df$svd_tsne2)
gg_df <- data.frame(gg_df, add_df)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(svd_tsne1 = median(svd_tsne1), svd_tsne2 = median(svd_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "svd_tsne1", y = "svd_tsne2", col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters SVD tSNE")
```

Note that the batch effect has been somewhat mitigated.

```{r}
dim_red_plot(
  data = gg_df, x = "svd_tsne1", y = "svd_tsne2", col = "cell_id_stem", type = "other") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Sample Distribution SVD tSNE")
dim_red_plot(
  data = gg_df, x = "svd_tsne1", y = "svd_tsne2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("log10(Total Features) SVD tSNE")
```

## HVG

HVGs are those that exhibit a high amount of biological signal relative to background noise and can often offer better clustering performance than using all genes in a dataset.
As we do not have spike-in transcripts, we choose to model the technical noise as Poisson and create a fitted trend on that basis.
Dimensionality reduction sections follow a slightly abbreviated version of the workflow described earlier.

```{r}
fit <- trendVar(sce, use.spikes = FALSE, loess.args = list(span = 0.05))
par(mfrow = c(1, 1), mar = c(5, 4, 2, 1), bty = "n")
plot(
  fit$mean, fit$var, pch = 20,
  col = rgb(0.1, 0.2, 0.7, 0.6), xlab = "log(Mean)", ylab = "Variance")
curve(fit$trend(x), col = "orange", lwd = 2, add = TRUE)
curve(new_trend(x), col = "red", lwd = 2, add = TRUE)
legend(
  "top", legend = c("Poisson Noise", "Observed Trend"), lty = 1,
  lwd = 2, col = c("red", "orange"), bty = "n")
```

The plot shows a large discrepancy between the two trends, which we assume is contributed by each gene's biological component.
We extract the genes with the largest biological components and plot them here.

```{r}
fit$trend <- new_trend
dec <- decomposeVar(fit = fit)
rm(fit)
plotExpression(sce, features = rownames(dec[order(dec$bio, decreasing = TRUE), ])[1:10])
```

We select HVGs by their FDR values, using a standard threshold of less than or equal to 0.05, and create a new SCE object with the subset data.

```{r}
par(mfrow = c(1, 2))
hist(log10(dec$FDR), breaks = 100, main = "")
hist(log10(dec$bio), breaks = 100, main = "")

keep <- which(dec$FDR <= 0.05)
sce_hvg <- sce[keep, ]
rm(dec)
sce_hvg
```

### PCA

#### denoisePCA

```{r}
new_trend <- makeTechTrend(x = sce_hvg)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "hvg_denoise_pca.rds")
if (file.exists(rds)) {
  denoise_pca <- readRDS(rds)
} else {
  denoise_pca <- denoisePCA(sce_hvg, technical = new_trend, BSPARAM = IrlbaParam())
  saveRDS(denoise_pca, rds)}
```

```{r}
sce_hvg <- denoise_pca
add_df <- data.frame(reducedDim(sce_hvg, "PCA"))
names(add_df) <- paste0("hvg_denoise_pc", seq(ncol(add_df)))
colData(sce_hvg) <- cbind(
  colData(sce_hvg), hvg_denoise_pc1 = add_df$hvg_denoise_pc1,
  hvg_denoise_pc2 = add_df$hvg_denoise_pc2)
colData(sce) <- cbind(
  colData(sce), hvg_denoise_pc1 = add_df$hvg_denoise_pc1, hvg_denoise_pc2 = add_df$hvg_denoise_pc2)
gg_df <- data.frame(gg_df, add_df[1:2])
rm(denoise_pca)
```

```{r}
par(mfrow = c(1, 1))
plot(
  log10(attr(reducedDim(sce_hvg), "percentVar")), xlab = "PC",
  ylab = "log10(Proportion of Variance Explained)", pch = 20,
  cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = 34, lty = 2, col = "red")
```

#### SVD PCA

```{r}
edat <- t(as.matrix(logcounts(sce_hvg)))
edat <- scale(edat)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "hvg_ppk.rds")
if (file.exists(rds)) {
  ppk <- readRDS(rds)
} else {
  ppk <- propack.svd(edat, neig = 34)
  saveRDS(ppk, rds)}
```

```{r}
svd_pca <- t(ppk$d * t(ppk$u))
add_df <- data.frame(svd_pca)
names(add_df) <- paste0("hvg_svd_pc", seq(ncol(add_df)))
colData(sce_hvg) <- cbind(
  colData(sce_hvg), hvg_svd_pc1 = add_df$hvg_svd_pc1, hvg_svd_pc2 = add_df$hvg_svd_pc2)
colData(sce) <- cbind(
  colData(sce), hvg_svd_pc1 = add_df$hvg_svd_pc1, hvg_svd_pc2 = add_df$hvg_svd_pc2)
gg_df <- data.frame(gg_df, add_df[1:2])
rm(edat)

dim_red_plot(
  data = gg_df, x = "hvg_svd_pc1", y = "hvg_svd_pc2", col = "habib_cluster_name", type = "other") +
  xlab("PC1") + ylab("PC2") + ggtitle("Habib Clusters HVG SVD PCA")
```

### tSNE

For brevity, we only focus on SVG PCs due their robustness against the influence of batch effects.

#### SVD PCA tSNE

```{r, cache = FALSE}
rds <- file.path(assets_dir, "cache", "hvg_svd_tsne.rds")
if (file.exists(rds)) {
  tsne <- readRDS(rds)
} else {
  set.seed(1)
  tsne <- Rtsne(svd_pca, pca = FALSE, perplexity = 100)
  saveRDS(tsne, rds)}
```

```{r}
reducedDims(sce_hvg) <- SimpleList(PCA = svd_pca, TSNE = tsne$Y)
add_df <- data.frame(reducedDim(sce_hvg, "TSNE"))
names(add_df) <- paste0("hvg_svd_tsne", seq(ncol(add_df)))
colData(sce_hvg) <- cbind(
  colData(sce_hvg), hvg_svd_tsne1 = add_df$hvg_svd_tsne1, hvg_svd_tsne2 = add_df$hvg_svd_tsne2)
colData(sce) <- cbind(
  colData(sce), hvg_svd_tsne1 = add_df$hvg_svd_tsne1, hvg_svd_tsne2 = add_df$hvg_svd_tsne2)
gg_df <- data.frame(gg_df, add_df)
rm(svd_pca, tsne)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(hvg_svd_tsne1 = median(hvg_svd_tsne1), hvg_svd_tsne2 = median(hvg_svd_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2", col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters HVG SVD tSNE")
dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2", col = "cell_id_stem", type = "other") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Sample Distribution HVG SVD tSNE")
dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("log10(Total Features) HVG SVD tSNE")
```

# Clustering

The previous sections utilized cluster labels provided in @habib_massively_2017, so now we will see if we can generate clusters that replicate them.
We opt to use HVGs for both cluster input and the tSNE coordinates as they appear to be in better agreeance with the original publication, particularly in the GABA, exPFC2, and exCA1 clusters.

## Seurat

We start our clustering approach with Seurat as it is graph-based like the approach used in @habib_massively_2017.
Seurat also heuristically selects the number of clusters as opposed to the user providing it a-priori, though this can be largely influenced by the `resolution` parameter in `FindClusters`.
Although we know the number of clusters we intend to replicate, due to differences in algorithmic implementations, greater accuracy may be achieved with slightly more or less clusters.

```{r}
seurat <- as.Seurat(sce, counts = "counts", data = NULL)

# nfeatures is set to the number of HVGs obtained earlier.
seurat <- FindVariableFeatures(seurat, selection.method = "vst", nfeatures = 6941)

seurat <- ScaleData(seurat, rownames(seurat))
seurat <- RunPCA(seurat, features = VariableFeatures(object = seurat))
```

As done earlier, we choose the number of PCs for downstream analysis by visually identifying a dropoff in explained variance.
In this case, the value chosen is 31.

```{r}
ElbowPlot(seurat, ndims = 50)
```

```{r}
seurat <- RunTSNE(object = seurat, dims = 1:31, check_duplicates = FALSE)
seurat <- FindNeighbors(seurat, dims = 1:31)
seurat <- FindClusters(seurat, resolution = 0.6)
gg_df$seurat_clusters <- seurat$seurat_clusters
head(Idents(seurat), 4)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_clusters = levels(gg_df$seurat_clusters), label = levels(gg_df$seurat_clusters))
label_df2 <- gg_df %>%
  group_by(seurat_clusters) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "seurat_clusters", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Seurat Clusters Habib tSNE")
```

## k-means

Although our Seurat clusters have some level of agreement with the tSNE from @habib_massively_2017, we see noticeable deviation as well.
As an alternative method, we try applying a simple k-means using selected PCs and the HVGs.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "km_18.rds")
if (file.exists(rds)) {
  km_18 <- readRDS(rds)
} else {
  km_18 <- kmeans(
    reducedDim(sce_hvg, "PCA"), centers = 18, iter.max = 1e8, nstart = 2500, algorithm = "MacQueen")
  saveRDS(km_18, rds)}
```

```{r}
gg_df$km_18_clusters <- as.factor(km_18$cluster)
rm(km_18)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_18_clusters = levels(gg_df$km_18_clusters), label = levels(gg_df$km_18_clusters))
label_df2 <- gg_df %>%
  group_by(km_18_clusters) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "km_18_clusters", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("KM 18 Clusters Habib tSNE")
```

Interestingly, it appears that our k-means clusters have greater overlap with the tSNE from @habib_massively_2017, though this is not true for all clusters, such the exCA ones.

## Labeling {.tabset}

Finally, we conclude our analysis by assigning labels for the new clusters based on their proximity to the clusters in the original paper and visualize them using various tSNE coordinates.

```{r}
gg_df$seurat_clusters_name <- NA
seurat_clusters <- as.integer(gg_df$seurat_clusters)
for (i in 1:length(seurat_clusters)) {
  if (seurat_clusters[i] == 1) {
    gg_df[i, ncol(gg_df)] <- "exPFC1"
  } else if (seurat_clusters[i] == 2) {
    gg_df[i, ncol(gg_df)] <- "exDG"
  } else if (seurat_clusters[i] == 3) {
    gg_df[i, ncol(gg_df)] <- "ODC1"
  } else if (seurat_clusters[i] == 4) {
    gg_df[i, ncol(gg_df)] <- "GABA1"
  } else if (seurat_clusters[i] == 5) {
    gg_df[i, ncol(gg_df)] <- "ASC1"
  } else if (seurat_clusters[i] == 6) {
    gg_df[i, ncol(gg_df)] <- "ODC2"
  } else if (seurat_clusters[i] == 7) {
    gg_df[i, ncol(gg_df)] <- "exPFC2.1"
  } else if (seurat_clusters[i] == 8) {
    gg_df[i, ncol(gg_df)] <- "exCA1"
  } else if (seurat_clusters[i] == 9) {
    gg_df[i, ncol(gg_df)] <- "OPC"
  } else if (seurat_clusters[i] == 10) {
    gg_df[i, ncol(gg_df)] <- "MG"
  } else if (seurat_clusters[i] == 11) {
    gg_df[i, ncol(gg_df)] <- "ASC2"
  } else if (seurat_clusters[i] == 12) {
    gg_df[i, ncol(gg_df)] <- "END"
  } else if (seurat_clusters[i] == 13) {
    gg_df[i, ncol(gg_df)] <- "GABA2.2"
  } else if (seurat_clusters[i] == 14) {
    gg_df[i, ncol(gg_df)] <- "exCA1"
  } else if (seurat_clusters[i] == 15) {
    gg_df[i, ncol(gg_df)] <- "Unlabeled1"
  } else if (seurat_clusters[i] == 16) {
    gg_df[i, ncol(gg_df)] <- "NSC"
  } else if (seurat_clusters[i] == 17) {
    gg_df[i, ncol(gg_df)] <- "exPFC2.2"
  } else if (seurat_clusters[i] == 18) {
    gg_df[i, ncol(gg_df)] <- "Unlabeled2"}}
seurat_clusters_id <- c(
  "exPFC1", "exDG", "ODC1", "GABA1", "ASC1", "ODC2", "exPFC2.1", "exCA1", "OPC",
  "MG", "ASC2", "END", "GABA2.2", "exCA1", "Unlabeled1", "NSC", "exPFC2.2", "Unlabeled2")
names(seurat_clusters_id) <- levels(seurat)
seurat <- RenameIdents(seurat, seurat_clusters_id)

gg_df$km_18_clusters_name <- NA
km_18_clusters <- as.integer(gg_df$km_18_clusters)
for (i in 1:length(km_18_clusters)) {
  if (km_18_clusters[i] == 1) {
    gg_df[i, ncol(gg_df)] <- "MG"
  } else if (km_18_clusters[i] == 2) {
    gg_df[i, ncol(gg_df)] <- "exCA"
  } else if (km_18_clusters[i] == 3) {
    gg_df[i, ncol(gg_df)] <- "Unlabeled2.2"
  } else if (km_18_clusters[i] == 4) {
    gg_df[i, ncol(gg_df)] <- "ASC1"
  } else if (km_18_clusters[i] == 5) {
    gg_df[i, ncol(gg_df)] <- "END1"
  } else if (km_18_clusters[i] == 6) {
    gg_df[i, ncol(gg_df)] <- "GABA2"
  } else if (km_18_clusters[i] == 7) {
    gg_df[i, ncol(gg_df)] <- "Unlabeled2.1"
  } else if (km_18_clusters[i] == 8) {
    gg_df[i, ncol(gg_df)] <- "ODC2"
  } else if (km_18_clusters[i] == 9) {
    gg_df[i, ncol(gg_df)] <- "exPFC"
  } else if (km_18_clusters[i] == 10) {
    gg_df[i, ncol(gg_df)] <- "exDG"
  } else if (km_18_clusters[i] == 11) {
    gg_df[i, ncol(gg_df)] <- "END2"
  } else if (km_18_clusters[i] == 12) {
    gg_df[i, ncol(gg_df)] <- "GABA1"
  } else if (km_18_clusters[i] == 13) {
    gg_df[i, ncol(gg_df)] <- "OPC"
  } else if (km_18_clusters[i] == 14) {
    gg_df[i, ncol(gg_df)] <- "Unlabeled1"
  } else if (km_18_clusters[i] == 15) {
    gg_df[i, ncol(gg_df)] <- "ASC2"
  } else if (km_18_clusters[i] == 16) {
    gg_df[i, ncol(gg_df)] <- "END3"
  } else if (km_18_clusters[i] == 17) {
    gg_df[i, ncol(gg_df)] <- "NSC"
  } else if (km_18_clusters[i] == 18) {
    gg_df[i, ncol(gg_df)] <- "ODC1"}}

colData(sce_hvg) <- cbind(
  colData(sce_hvg), seurat_clusters = gg_df$seurat_clusters,
  seurat_clusters_name = gg_df$seurat_clusters_name, km_18_clusters = gg_df$km_18_clusters,
  km_18_clusters_name = gg_df$km_18_clusters_name)
colData(sce) <- cbind(
  colData(sce), seurat_clusters = gg_df$seurat_clusters,
  seurat_clusters_name = gg_df$seurat_clusters_name, km_18_clusters = gg_df$km_18_clusters,
  km_18_clusters_name = gg_df$km_18_clusters_name)
gg_df$seurat_clusters_name <- as.factor(gg_df$seurat_clusters_name)
gg_df$km_18_clusters_name <- factor(gg_df$km_18_clusters_name)
names(colData(sce))
```

### Seurat Clusters Habib tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_clusters_name = levels(gg_df$seurat_clusters_name),
  label = levels(gg_df$seurat_clusters_name))
label_df2 <- gg_df %>%
  group_by(seurat_clusters_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "seurat_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Seurat Clusters Habib tSNE")
```

### KM 18 Clusters Habib tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_18_clusters_name = levels(gg_df$km_18_clusters_name),
  label = levels(gg_df$km_18_clusters_name))
label_df2 <- gg_df %>%
  group_by(km_18_clusters_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "km_18_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("KM 18 Clusters Habib tSNE")
```

### Habib Clusters Habib tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name), label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2",col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters Habib tSNE")
```

### Seurat Clusters Seurat tSNE

```{r}
DimPlot(object = seurat, reduction = "tsne", label = TRUE)
```

### KM 18 Clusters HVG SVD tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_18_clusters_name = levels(gg_df$km_18_clusters_name),
  label = levels(gg_df$km_18_clusters_name))
label_df2 <- gg_df %>%
  group_by(km_18_clusters_name) %>%
  summarize(hvg_svd_tsne1 = median(hvg_svd_tsne1), hvg_svd_tsne2 = median(hvg_svd_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2", col = "km_18_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("KM 18 Clusters HVG SVD tSNE")
```

### Habib Clusters HVG SVD tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name), label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(hvg_svd_tsne1 = median(hvg_svd_tsne1), hvg_svd_tsne2 = median(hvg_svd_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2", col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters HVG SVD tSNE")
```

# References

This is the concluding section of the document.
Here we write relevant results to disk, output the `sessionInfo`, and create a bibliography for works cited.

```{r}
saveRDS(sce, file.path(results_dir, "data", "sce.rds"))
saveRDS(sce_hvg, file.path(results_dir, "data", "sce_hvg.rds"))
saveRDS(seurat, file.path(results_dir, "data", "seurat.rds"))
sessionInfo()
```
