---
title: "Habib 2017 snRNAseq Report"
author:
  - name: "Emir Turkes [et2628@cumc.columbia.edu]"
  - name: "Columbia University"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: "../habib-2017-snRNAseq.bib"
biblio-style: apalike
link-citations: true
output:
  html_document:
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit:
  (function(inputFile, encoding) {
    rmarkdown::render(
      inputFile, encoding = encoding, output_file = "../results/habib-2017-snRNAseq-report.html")})
---

```{r, include = FALSE}
#    This file is part of habib-2017-snRNAseq.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

knitr::opts_chunk$set(fig.width = 8.5, fig.height = 7)
```

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This is a broad initial analysis that prepares and characterizes the data for use in other projects.*

The background for this data is as follows:

- dbGaP Accession: [phs000424](https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000424.v7.p2).
- Part of [GTEx](https://gtexportal.org/home/) and originally published in @habib_massively_2017.
- Archived frozen adult human post-mortem tissue.
- 19,550 nuclei, 1,683 genes, 2,187 transcripts.
- 3 PFC samples, 4 hippocampus samples from 5 donors.

This analysis was performed in R except where noted.
The source code and instructions for rerunning the analysis can be found at [github.com/eturkes/habib-2017-snRNAseq](https://github.com/eturkes/habib-2017-snRNAseq).

# Final Results

**Read just the following sub-sections (1.1-1.2) for the final results of the analysis and a brief summary of the methods.**

```{r, include = FALSE}
packages <- c(
  "conflicted", "BiocFileCache", "data.table", "DT", "SingleCellExperiment", "biomaRt", "S4Vectors",
  "dplyr", "SummarizedExperiment", "DropletUtils", "scater", "scran", "ggrepel", "BiocSingular",
  "ggplot2", "svd", "Rtsne", "knitr", "kableExtra", "Seurat")
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))

options(stringsAsFactors = FALSE)

results_dir <- file.path(getwd(), "..", "results")

# ggplot2 function providing custom aesthetics and automatic placement of categorical labels.
# For continuous data, a colorbar is implemented.
dim_red_plot <- function(data, x, y, col, type) {
  gg <- ggplot(data, aes_string(x = x, y = y, color = col)) +
    geom_point(alpha = 0.35, stroke = 0.05, shape = 21, aes_string(fill = col)) +
    theme_classic() +
    theme(
      legend.position = "right", plot.title = element_text(hjust = 0.5),
      legend.title = element_blank()) +
    guides(color = guide_legend(override.aes = list(alpha = 1)))
    if (type == "cat") {
      gg <- gg + geom_label_repel(data = label_df2, aes(label = label), show.legend = FALSE)
    } else if (type == "cont") {
      gg <- ggplot(data, aes_string(x = x, y = y)) +
        geom_point(alpha = 0.35, stroke = 0.05, aes_string(color = col)) +
        theme_classic() +
        theme(
          legend.position = "right", plot.title = element_text(hjust = 0.5),
          legend.title = element_blank()) +
        scale_colour_gradient(low = "blue", high = "red")}
  gg}

sce <- readRDS(file.path(results_dir, "data", "sce.rds"))
sce_hvg <- readRDS(file.path(results_dir, "data", "sce_hvg.rds"))
```

## SCE Object of Original Data

The dataset in @habib_massively_2017 includes transcript counts, cluster labels, and tSNE coordinates.
However, in order to transform the data to the main figures seen in the paper, additional QC was required.
The protocol described in @habib_massively_2017 was followed where possible and included the addition of gene annotations, the removal of low-quality cells, the removal of mitochondrial/ribosomal genes, the removal of lowly-expressed genes, and normalization.
The data was also transformed into an SCE (SingleCellExperiment) object, which facilitates easy interface with popular software packages.
This SCE object, along with one subsetted to the top ~1,000 HVGs (highly variable genes), are included in the `results/data/` directory of this project.

```{r, message = FALSE}
sce
sce_hvg
```

## Reproduction and Replication {.tabset}

The below tabs display reproductions and replications of the results in @habib_massively_2017.
Note that the cluster "Unlabeled2", corresponding to Cluster 17, is removed, as it was determined to be entirely composed of ribosomal cells.
This cluster, as well as the other "Unlabeled" clusters, do not appear in the final figures of @habib_massively_2017, but we include them here.
Overall, it can be seen that our reproduction and replication of the results in @habib_massively_2017 agree well with the original publication.

```{r, include = FALSE}
# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    paste0("habib_tsne", 1:2), paste0("hvg_tsne", 1:2), "habib_cluster_name", "km_17_clusters_name")])
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)
gg_df$km_17_clusters_name <- factor(gg_df$km_17_clusters_name)
```

### Habib Clusters Habib tSNE

The original clusters and tSNE coordinates.

```{r, echo = FALSE, message = FALSE}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name), label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters Habib tSNE")
```

### KM Clusters Habib tSNE

New clusters generated by k-means atop the first 50 PCs (principal components) with the original tSNE coordinates.

```{r, echo = FALSE, message = FALSE}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_17_clusters_name = levels(gg_df$km_17_clusters_name),
  label = levels(gg_df$km_17_clusters_name))
label_df2 <- gg_df %>%
  group_by(km_17_clusters_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "km_17_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("KM Clusters Habib tSNE")
```

### Habib Clusters New tSNE

The original clusters with new tSNE coordinates based on HVGs (highly variable genes).

```{r, echo = FALSE, message = FALSE}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name), label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(hvg_tsne1 = median(hvg_tsne1), hvg_tsne2 = median(hvg_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_tsne1", y = "hvg_tsne2", col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters New tSNE")
```

### KM Clusters New tSNE

The new k-means clusters and tSNE coordinates.

```{r, echo = FALSE, message = FALSE}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_17_clusters_name = levels(gg_df$km_17_clusters_name),
  label = levels(gg_df$km_17_clusters_name))
label_df2 <- gg_df %>%
  group_by(km_17_clusters_name) %>%
  summarize(hvg_tsne1 = median(hvg_tsne1), hvg_tsne2 = median(hvg_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_tsne1", y = "hvg_tsne2", col = "km_17_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("KM Clusters New tSNE")
```

# ~~~ Breakdown of Methods ~~~ {-}

**Sections from here to the end break down the methods used and are optional to read.**

We start by loading in any required packages and setting some global variables.

```{r}
packages <- c(
  "conflicted", "BiocFileCache", "data.table", "DT", "SingleCellExperiment", "biomaRt", "S4Vectors",
  "dplyr", "SummarizedExperiment", "DropletUtils", "scater", "scran", "ggrepel", "BiocSingular",
  "ggplot2", "svd", "Rtsne", "knitr", "kableExtra", "Seurat")
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))

options(stringsAsFactors = FALSE)

data_str <- "GTEx_droncseq_hip_pcf"
data_dir <- file.path(getwd(), "..", "data")
assets_dir <- file.path(getwd(), "..", "assets")
results_dir <- file.path(getwd(), "..", "results")

# Create a cache for storing the objects of long-running computations.
if (!dir.exists(file.path(assets_dir, "cache"))) {
  dir.create(file.path(assets_dir, "cache"))}

# ggplot2 function providing custom aesthetics and automatic placement of categorical labels.
# For continuous data, a colorbar is implemented.
dim_red_plot <- function(data, x, y, col, type) {
  gg <- ggplot(data, aes_string(x = x, y = y, color = col)) +
    geom_point(alpha = 0.35, stroke = 0.05, shape = 21, aes_string(fill = col)) +
    theme_classic() +
    theme(
      legend.position = "right", plot.title = element_text(hjust = 0.5),
      legend.title = element_blank()) +
    guides(color = guide_legend(override.aes = list(alpha = 1)))
    if (type == "cat") {
      gg <- gg + geom_label_repel(data = label_df2, aes(label = label), show.legend = FALSE)
    } else if (type == "cont") {
      gg <- ggplot(data, aes_string(x = x, y = y)) +
        geom_point(alpha = 0.35, stroke = 0.05, aes_string(color = col)) +
        theme_classic() +
        theme(
          legend.position = "right", plot.title = element_text(hjust = 0.5),
          legend.title = element_blank()) +
        scale_colour_gradient(low = "blue", high = "red")}
  gg}
```

# Original Data {.tabset}

This section provides a brief look at the raw data before manipulation.

```{r}
bfc <- BiocFileCache(data_dir, ask = FALSE)
data <- bfcrpath(bfc, file.path(
  "https://storage.googleapis.com/gtex_additional_datasets/single_cell_data",
  paste0(data_str, ".tar")))
untar(data, exdir = tempdir())
rm(bfc)
```

## Counts

```{r}
counts <- fread(
  file.path(tempdir(), data_str, paste0(data_str, ".umi_counts.txt.gz")), data.table = FALSE)
datatable(counts[1:5, 1:3])
```

## Clusters

```{r}
# The original clusters file, GTEx_droncseq_hip_pcf.clusters.txt, has several inconsistencies.
# Specifically in clusters 15-18, which do not match those in the original publication.
# Therefore we use Supplementary Table 7 (nmeth.4407-S10.xlsx), which does not have those issues.
# However, because cluster 11 is incorrectly named in this table, we must correct that.
# Also, as this file contained non-standard formatting, minimal manual editing was done for use in R.
clust <- fread(file.path(assets_dir, "nmeth.4407-S10-edited.txt"), data.table = FALSE)
datatable(clust[1:5, ])
```

## tSNE

```{r}
tsne <- fread(file.path(tempdir(), data_str, paste0(data_str, ".tsne.txt.gz")), data.table = FALSE)
datatable(tsne[1:5, ])
```

# Preliminary Cleaning

Here we do any data wrangling neccessary to transform the data into more convenient formats for downstream analysis.

## Counts

```{r}
rownames(counts) <- counts[ , 1]
counts <- as.matrix(counts[ , -1])
cell_id_stem <- sapply(colnames(counts), function(xx) strsplit(xx, "_")[[1]][1], USE.NAMES = FALSE)
col_dat <- data.frame(sample = colnames(counts), cell_id_stem = cell_id_stem, check.names = FALSE)
datatable(counts[1:5, 1:3])

# Convert to dgCMatrix after datatable, as they are incompatible.
counts <- Matrix::Matrix(counts, sparse = TRUE)
```

## Clusters

```{r}
# Fix mislabeled cluster name and give unique names for unclassified clusters.
for (i in seq_len(nrow(clust))) {
  if (clust[i, 4] == 11) {
    clust[i, 5] <- "ODC2"
  } else if (clust[i, 4] == 16) {
    clust[i, 5] <- "Unlabeled1"
  } else if (clust[i, 4] == 17) {
    clust[i, 5] <- "Unlabeled2"
  } else if (clust[i, 4] == 18) {
    clust[i, 5] <- "Unlabeled3"}}

clust <- clust[ , -c(2:3)]
names(clust) <- c("sample", "habib_cluster", "habib_cluster_name")
clust$habib_cluster <- as.factor(clust$habib_cluster)
clust <- clust[match(col_dat$sample, clust$sample), ]
rownames(clust) <- NULL
datatable(clust[1:5, ])
```

## tSNE

```{r}
names(tsne) = c("sample", paste0("habib_tsne", 1:2))
datatable(tsne[1:5, ])
```

## SingleCellExperiment

The data is now sufficiently prepared to form a SingleCellExperiment (SCE) object.

```{r}
col_dat <- cbind(col_dat, clust[ , names(clust) != "sample"], tsne[ , names(tsne) != "sample"])
sce <- SingleCellExperiment(assays = list(counts = counts), colData = col_dat)
rm(clust, tsne)
sce
```

## Seurat

Analysis with Seurat requires use of a Seurat class object.
As a typical Seurat analysis uses its own QC steps, we diverge the two objects here.

```{r}
seurat <- CreateSeuratObject(counts = counts, meta.data = col_dat)
rm(counts, col_dat)
seurat
```

## Gene Annotations

We add annotations based on the hg19 reference gnome, the same used in @habib_massively_2017.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "gene_anno.rds")
if (file.exists(rds)) {
  gene_anno <- readRDS(rds)
} else {
  ensembl <- useEnsembl(biomart = "ensembl", GRCh = 37, dataset = "hsapiens_gene_ensembl")
  attr_string <- c(
    "hgnc_symbol", "ensembl_gene_id", "external_gene_name", "chromosome_name", "start_position",
    "end_position", "strand", "description", "percentage_gene_gc_content", "gene_biotype")
  gene_anno <- getBM(
    attributes = attr_string, filters = "external_gene_name", values = rownames(sce), mart = ensembl)
  rm(ensembl)
  saveRDS(gene_anno, rds)}
```

Before merging them into the SCE and Seurat objects, the annotation must be cleaned by removing genes not in the RNAseq dataset, irrelevant annotations, duplicate genes, and genes that are not annotated.

```{r}
# Remove genes not in the RNAseq dataset.
remove_genes <- which(!gene_anno$external_gene_name %in% rownames(sce))
gene_anno <- gene_anno[-remove_genes, ]

# Remove annotations to scaffolds, assembly patches, and alternative loci.
chromosomes <- c(1:22, "X", "Y", "MT")
gene_anno <- gene_anno[which(gene_anno$chromosome_name %in% chromosomes), ]

# Remove duplicates.
dup <- table(gene_anno$external_gene_name)
dup <- sort(dup[dup > 1], decreasing = TRUE)
dup <- which(gene_anno$external_gene_name %in% names(dup))
gene_anno2 <- gene_anno[dup, ]
gene_anno2 <- gene_anno2[which(gene_anno2$hgnc_symbol == gene_anno2$external_gene_name), ]
gene_anno2 <- distinct(gene_anno2, external_gene_name, .keep_all = TRUE)
gene_anno <- rbind(gene_anno[-dup, ], gene_anno2)

# Remove missing.
keep_genes <- match(gene_anno$external_gene_name, rownames(sce))
sce <- sce[keep_genes, ]
seurat <- seurat[keep_genes, ]

rowData(sce) <- gene_anno
seurat <- AddMetaData(seurat, metadata = gene_anno)
rm(gene_anno, gene_anno2)
names(rowData(sce))
```

# QC

These sections assess and correct issues and irregularities in the dataset.

## Low Quality Cells

### SCE

In order to remove droplets which do not contain a cell but are rather ambient RNA, we visualize the inflection point on a knee plot, as described originally in @macosko_highly_2015.
Removal was then to be originally done using `emptyDrops` from the `DropletUtils` package, but due to an unresolved error (`no counts available to estimate the ambient profile`), we skip it.
In any case, all 14,963 cells were used in the original analysis in @habib_massively_2017, so this step is not crucial.

```{r}
bc_rank <- barcodeRanks(counts(sce))
uniq <- !duplicated(bc_rank$rank)

par(mar = c(5, 4, 2, 1), bty = "n")
plot(
  bc_rank$rank[uniq], bc_rank$total[uniq], log = "xy", xlab = "Rank",
  ylab = "Total UMI Count", cex = 0.5, cex.lab = 1.2)
abline(h = metadata(bc_rank)$inflection, col = "darkgreen", lty = 2, lwd = 2)
abline(h = metadata(bc_rank)$knee, col = "dodgerblue", lty = 2, lwd = 2)
legend(
  "left", legend = c("Inflection", "Knee"), bty = "n", col = c("darkgreen", "dodgerblue"),
  lty = 2, cex = 1.2, lwd = 2)
```

```{r, cache = TRUE}
# Commented out due to "no counts available to estimate the ambient profile" error.
# rds <- file.path(assets_dir, "cache", "e_out.rds")
# if (file.exists(rds)) {
#   e_out <- readRDS(rds)
# } else {
#   set.seed(1)
#   e_out <- emptyDrops(counts(sce))
#   saveRDS(e_out, rds)}
```

Using an annotation from [HGNC](https://www.genenames.org/), we assess the proportion of mitochondrial/ribosomal genes within the cells.

```{r}
ribo_genes <- read.table(file.path(assets_dir, "ribo-genes.txt"), sep = "\t", header = TRUE)
is_mito <- which(rowData(sce)$chromosome_name == "MT")
is_ribo <- which(rowData(sce)$external_gene_name %in% ribo_genes$Approved.Symbol)
sce <- calculateQCMetrics(sce, feature_controls = list(Mt = is_mito, Ri = is_ribo))
rm(ribo_genes, bc_rank)

par(mfrow = c(2, 2), mar = c(5, 4, 1, 1), bty = "n")
hist(
  log10(sce$total_counts), xlab = "log10(Library Sizes)", main = "",
  breaks = 20, col = "grey80", ylab = "Number of Cells")
hist(
  log10(sce$total_features_by_counts), xlab = "log10(Number of Expressed Genes)", main = "",
  breaks = 20, col = "grey80", ylab = "Number of Cells")
hist(
  sce$pct_counts_Ri, xlab = "Ribosomal Proportion Percentage", ylab = "Number of Cells",
  breaks = 40, main = "", col = "grey80")
hist(
  sce$pct_counts_Mt, xlab = "Mitochondrial Proportion Percentage", ylab = "Number of Cells",
  breaks = 80, main = "", col = "grey80")
par(mfrow = c(2, 2), mar = c(5, 4, 1, 1), bty = "n")
smoothScatter(
  log10(sce$total_counts), log10(sce$total_features_by_counts),
  xlab = "log10(Library Sizes)", ylab = "log10(Num. Expressed Genes)")
smoothScatter(
  log10(sce$total_counts), sce$pct_counts_Ri,
  xlab = "log10(Library Sizes)", ylab = "Ribosomal Proportion %")
smoothScatter(
  log10(sce$total_counts), sce$pct_counts_Mt,
  xlab = "log10(Library Sizes)", ylab = "Mitochondrial Proportion %")
smoothScatter(
  sce$pct_counts_Ri,sce$pct_counts_Mt, xlab = "Ribosomal Proportion %",
  ylab = "Mitochondrial Proportion %")
```

We then use the `isOutlier` function from `scater` to remove cells with an overabundance of mitochondrial/ribosomal gene expression, as these are likely to be damaged cells.
We also remove cells determined to be low quality by their library size and feature counts.
In the table below, "TRUE" indicates cells that are kept.
It should be noted that all cells in Cluster 17 are determined to be low quality do to their ribosomal gene expression, and thus removed.

```{r}
libsize_drop <- isOutlier(sce$total_counts, nmads = 3, type = "lower", log = TRUE)
feature_drop <- isOutlier(sce$total_features_by_counts, nmads = 3, type = "lower", log = TRUE)
mito_drop <- isOutlier(sce$pct_counts_Mt, nmads = 3, type = "higher")
ribo_drop <- isOutlier(sce$pct_counts_Ri, nmads = 3, type = "higher")
keep <- !(libsize_drop | feature_drop | mito_drop | ribo_drop)
kable(table(colData(sce)$habib_cluster, keep), row.names = TRUE, padding = 0) %>%
  kable_styling(bootstrap_options = "striped", font_size = 13, full_width = FALSE, position = "left")

sce <- sce[ , keep]
dim(sce)
```

### Seurat

We carry out the closest equivalent to the above operations on our Seurat object as well.

```{r}
seurat[["percent.mt"]] <- PercentageFeatureSet(seurat, pattern = "^MT-")

VlnPlot(seurat, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
FeatureScatter(seurat, feature1 = "nCount_RNA", feature2 = "percent.mt")

plot1 <- FeatureScatter(seurat, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot2 <- FeatureScatter(seurat, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
CombinePlots(plots = list(plot1, plot2))

seurat <- subset(seurat, subset = nFeature_RNA > 200 & nFeature_RNA < 2500 & percent.mt < 5)
rm(plot1, plot2)
seurat
```

## Lowly Expressed Genes

### SCE

According to the original paper, nuclei that have less than 200 genes in one or more UMIs should be removed.
We start by first visualizing some gene-level summary statistics.

```{r}
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Cells + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Cells + 1)")
```

We remove genes as necessary and view the summary statistics again.

```{r}
names(rowData(sce))[names(rowData(sce)) == "strand"] <- "strand_n" # Must be renamed due to error.
n_genes <- colSums(counts(sce) >= 2)
n_genes <- colSums(counts(sce) >= 1)
n_cells <- rowSums(counts(sce) >= 2)
sce <- sce[which(n_cells >= 10), ]
dim(sce)

par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Cells + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Cells + 1)")
```

### Seurat

This QC step is not part of the standard Seurat workflow.
However, considering that HVGs are selected for all downstream analyses, it may not be neccessary.

## Normalization

### SCE

We use `computeSumFactors` from the `scran` package to perform normalization.
This function uses a linear deconvolution system to account for expected variation across different cell types/sizes [@l_lun_pooling_2016], producing "scale factor" values that indicates the extent to which a cell should be scaled.
For additional QC, we also remove cells that have size factors from the function that are very small ($< 0.01$) or negative.
In an experiment where most systematic differences between cells are driven by capture efficiency and sequencing depth, we should see a correlation between size factors and library size, so we visualize this.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "quickCluster.rds")
if (file.exists(rds)) {
  quickCluster <- readRDS(rds)
} else {
  quickCluster <- quickCluster(sce, use.ranks = FALSE, min.mean = 0.1, method = "igraph")
  saveRDS(quickCluster, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "size_factors.rds")
if (file.exists(rds)) {
  size_factors <- readRDS(rds)
} else {
  size_factors <- computeSumFactors(sce, cluster = quickCluster, min.mean = 0.1)
  saveRDS(size_factors, rds)}
```

```{r}
sce <- size_factors
sce <- sce[ , which(sizeFactors(sce) > 0.01)]
rm(size_factors)

par(mfrow = c(1, 2), mar = c(5, 4, 2, 1), bty = "n")
smoothScatter(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts", ylab = "Size Factors")
plot(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts",
  ylab = "Size Factors", cex = 0.3, pch = 20, col = rgb(0.1, 0.2, 0.7, 0.3))
abline(h = 0.05)
```

The plots are very well-correlated, which not only confirm the source of bias but also indicate that the previous QC steps were sufficient, therefore we go ahead and normalize the data.

```{r}
sce <- normalize(sce)
dim(sce)
```

### Seurat

We use the default `LogNormalize` method of Seurat, which normalizes the feature expression measurements for each cell by the total expression, multiplies this by the scale factor of 10,000, and log-transforms the result.

```{r}
seurat <- NormalizeData(seurat)
```

# Dimensionality Reduction

This section details steps taken to reduce the dimensionality of the dataset.
As this is only done on HVGs with Seurat, it is only included in the HVG section.
All other sections use all genes in the dataset.

## PCA

### denoisePCA

We start by applying `denoisePCA` from the `scran` package, which automatically selects PCs by modeling technical noise.

```{r}
new_trend <- makeTechTrend(x = sce)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "denoise_pca.rds")
if (file.exists(rds)) {
  denoise_pca <- readRDS(rds)
} else {
  denoise_pca <- denoisePCA(sce, technical = new_trend, BSPARAM = IrlbaParam())
  saveRDS(denoise_pca, rds)}
```

```{r}
sce <- denoise_pca
add_df <- data.frame(reducedDim(sce, "PCA"))
names(add_df) <- paste0("denoise_pc", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), denoise_pc1 = add_df$denoise_pc1, denoise_pc2 = add_df$denoise_pc2)

# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    "sample", "cell_id_stem", paste0("habib_tsne", 1:2),
    "log10_total_features_by_counts", "habib_cluster", "habib_cluster_name")],
  add_df[1:2])
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)
```

We use the first 14 PCs, chosen by visually identifying the dropoff in variance explained.

```{r}
par(mfrow = c(1, 1))
plot(
  log10(attr(reducedDim(sce), "percentVar")), xlab = "PC",
  ylab = "log10(Proportion of Variance Explained)", pch = 20,
  cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = 14, lty = 2, col = "red")
```

We take a closer look at the first four components and their ability to explain the cluster labels defined in @habib_massively_2017.

```{r}
plotPCA(sce, ncomponents = 4, colour_by = "habib_cluster_name") +
  ggtitle("Habib Clusters denoisePCA") + theme(legend.title = element_blank())
```

### SVD PCA

As an alternative, we also use a truncated SVD (singular value decomposition) method to generate PCs.
This approach was found to be less sensitive to the influence of batch effects.

```{r}
edat <- t(as.matrix(logcounts(sce)))
edat <- scale(edat)
```

We set the desired eigentriples to the number of components selected after inspecting the `denoisePCA` results.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "ppk.rds")
if (file.exists(rds)) {
  ppk <- readRDS(rds)
} else {
  ppk <- propack.svd(edat, neig = 14)
  saveRDS(ppk, rds)}
```

```{r}
svd_pca <- t(ppk$d * t(ppk$u))
add_df <- data.frame(svd_pca)
names(add_df) <- paste0("svd_pc", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), svd_pc1 = add_df$svd_pc1, svd_pc2 = add_df$svd_pc2)
gg_df <- data.frame(gg_df, add_df[1:2])

dim_red_plot(
  data = gg_df, x = "svd_pc1", y = "svd_pc2", col = "habib_cluster_name", type = "other") +
  xlab("PC1") + ylab("PC2") + ggtitle("Habib Clusters SVD PCA")
```

## tSNE

We plot the tSNE coordinates provided in @habib_massively_2017 as well create new ones off of the PCs just created.

### Habib

It should be noted that the tSNE coordinates provided were generated using HVGs, not all genes in the set.

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name),
  label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2",
  col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters Habib tSNE")
dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "cell_id_stem", type = "other") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Sample Distribution Habib tSNE")
dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("log10(Total Features) Habib tSNE")
```

### denoisePCA tSNE

We first try using the first 14 PCs from the `denoisePCA` function.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "denoise_tsne.rds")
if (file.exists(rds)) {
  tsne <- readRDS(rds)
} else {
  tsne <- runTSNE(sce, use_dimred = "PCA", n_dimred = 14, perplexity = 100, rand_seed = 1)
  saveRDS(tsne, rds)}
```

```{r}
sce <- tsne
add_df <- data.frame(reducedDim(sce, "TSNE"))
names(add_df) <- paste0("denoise_tsne", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), denoise_tsne1 = add_df$denoise_tsne1, denoise_tsne2 = add_df$denoise_tsne2)
gg_df <- data.frame(gg_df, add_df)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(denoise_tsne1 = median(denoise_tsne1), denoise_tsne2 = median(denoise_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "denoise_tsne1", y = "denoise_tsne2",
  col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters denoisePCA tSNE")
```

These PCs appear to drive a strong batch effect from certain hippocampal samples.

```{r}
dim_red_plot(
  data = gg_df, x = "denoise_tsne1", y = "denoise_tsne2",
  col = "cell_id_stem", type = "other") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Sample Distribution denoisePCA tSNE")
dim_red_plot(
  data = gg_df, x = "denoise_tsne1", y = "denoise_tsne2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("log10(Total Features) denoisePCA tSNE")
```

### SVD PCA tSNE

Next using the SVD PCs.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "svd_tsne.rds")
if (file.exists(rds)) {
  tsne <- readRDS(rds)
} else {
  set.seed(1)
  tsne <- Rtsne(svd_pca, pca = FALSE, perplexity = 100)
  saveRDS(tsne, rds)}
```

```{r}
reducedDims(sce) <- SimpleList(PCA = svd_pca, TSNE = tsne$Y)
add_df <- data.frame(reducedDim(sce, "TSNE"))
names(add_df) <- paste0("svd_tsne", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), svd_tsne1 = add_df$svd_tsne1, svd_tsne2 = add_df$svd_tsne2)
gg_df <- data.frame(gg_df, add_df)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name),
  label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(svd_tsne1 = median(svd_tsne1), svd_tsne2 = median(svd_tsne2)) %>%
  left_join(label_df)
dim_red_plot(
  data = gg_df, x = "svd_tsne1", y = "svd_tsne2", col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters SVD tSNE")
```

Note that the batch effect has been somewhat mitigated.

```{r}
dim_red_plot(
  data = gg_df, x = "svd_tsne1", y = "svd_tsne2", col = "cell_id_stem", type = "other") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Sample Distribution SVD tSNE")
dim_red_plot(
  data = gg_df, x = "svd_tsne1", y = "svd_tsne2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("log10(Total Features) SVD tSNE")
```

## HVG

HVGs are those that exhibit a high amount of biological signal relative to background noise and can often offer better clustering performance than using all genes in a dataset.
We start by plotting the variability of genes in our dataset against the expected Poisson technical noise.
For dimensionality reduction, we apply the same steps as above.

```{r}
fit <- trendVar(sce, use.spikes = FALSE, loess.args = list(span = 0.05))

par(mfrow = c(1, 1), mar = c(5, 4, 2, 1), bty = "n")
plot(
  fit$mean, fit$var, pch = 20,
  col = rgb(0.1, 0.2, 0.7, 0.6), xlab = "log(Mean)", ylab = "Variance")
curve(fit$trend(x), col = "orange", lwd = 2, add = TRUE)
curve(new_trend(x), col = "red", lwd = 2, add = TRUE)
legend(
  "top", legend = c("Poisson Noise", "Observed Trend"), lty = 1,
  lwd = 2, col = c("red", "orange"), bty = "n")
```

The plot shows a large discrepancy between the two trends, which is contributed by each gene's biological component.
We extract the genes with the largest biological components and plot them here.

```{r}
fit$trend <- new_trend
dec <- decomposeVar(fit = fit)
top_dec <- dec[order(dec$bio, decreasing = TRUE), ]
rm(fit)
plotExpression(sce, features = rownames(top_dec)[1:10])
```

For comparison, we also visualize the top 50 genes by total expression, not taking into account the components.

```{r}
plotHighestExprs(sce)
```

Finally, we select the top roughly 1,000 HVGs using their FDR and biological residual thresholds and visualize them below.

```{r}
dec1 <- dec
dec1$bio[which(dec$bio < 1e-72)] <- 1.5e-73
dec1$FDR[which(dec$FDR < 1e-5)] <- 1e-5

kable(table(dec$FDR < 1e-72, dec$bio > 1e-5), row.names = TRUE, padding = 0) %>%
  kable_styling(bootstrap_options = "striped", font_size = 13, full_width = FALSE, position = "left")
par(mfrow = c(1, 2))
hist(log10(dec1$bio), breaks = 100, main = "")
hist(log10(dec1$FDR), breaks = 100, main = "")
```

And create a new SCE object containing the subsetted data.

```{r}
keep <- which(dec$FDR < 1e-72 & dec$bio > 1e-5)
sce_hvg <- sce[keep, ]
rm(dec, dec1)
sce_hvg
```

### PCA

#### denoisePCA

```{r}
new_trend <- makeTechTrend(x = sce_hvg)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "hvg_denoise_pca.rds")
if (file.exists(rds)) {
  denoise_pca <- readRDS(rds)
} else {
  denoise_pca <- denoisePCA(sce_hvg, technical = new_trend, BSPARAM = IrlbaParam())
  saveRDS(denoise_pca, rds)}
```

```{r}
sce_hvg <- denoise_pca
add_df <- data.frame(reducedDim(sce_hvg, "PCA"))
names(add_df) <- paste0("hvg_denoise_pc", seq(ncol(add_df)))
colData(sce_hvg) <- cbind(
  colData(sce_hvg), hvg_denoise_pc1 = add_df$hvg_denoise_pc1,
  hvg_denoise_pc2 = add_df$hvg_denoise_pc2)
colData(sce) <- cbind(
  colData(sce), hvg_denoise_pc1 = add_df$hvg_denoise_pc1, hvg_denoise_pc2 = add_df$hvg_denoise_pc2)
gg_df <- data.frame(gg_df, add_df[1:2])
rm(denoise_pca)
```

We use the first 30 PCs, chosen by visually identifying the dropoff in variance explained.

```{r}
par(mfrow = c(1, 1))
plot(
  log10(attr(reducedDim(sce_hvg), "percentVar")), xlab = "PC",
  ylab = "log10(Proportion of Variance Explained)", pch = 20,
  cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = 30, lty = 2, col = "red")
```

We take a closer look at the first four components and their ability to explain the cluster labels defined in @habib_massively_2017.

```{r}
plotPCA(sce_hvg, ncomponents = 4, colour_by = "habib_cluster_name") +
  ggtitle("Habib Clusters HVG denoisePCA") + theme(legend.title = element_blank())
```

#### SVD PCA

```{r}
edat <- t(as.matrix(logcounts(sce_hvg)))
edat <- scale(edat)
```

We set the desired eigentriples to the number of components selected after inspecting the `denoisePCA` results.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "hvg_ppk.rds")
if (file.exists(rds)) {
  ppk <- readRDS(rds)
} else {
  ppk <- propack.svd(edat, neig = 30)
  saveRDS(ppk, rds)}
```

```{r}
svd_pca <- t(ppk$d * t(ppk$u))
add_df <- data.frame(svd_pca)
names(add_df) <- paste0("hvg_svd_pc", seq(ncol(add_df)))
colData(sce_hvg) <- cbind(
  colData(sce_hvg), hvg_svd_pc1 = add_df$hvg_svd_pc1, hvg_svd_pc2 = add_df$hvg_svd_pc2)
colData(sce) <- cbind(
  colData(sce), hvg_svd_pc1 = add_df$hvg_svd_pc1, hvg_svd_pc2 = add_df$hvg_svd_pc2)
gg_df <- data.frame(gg_df, add_df[1:2])
rm(edat)

dim_red_plot(
  data = gg_df, x = "hvg_svd_pc1", y = "hvg_svd_pc2", col = "habib_cluster_name", type = "other") +
  xlab("PC1") + ylab("PC2") + ggtitle("Habib Clusters HVG SVD PCA")
```

### tSNE

#### denoisePCA tSNE

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "hvg_denoise_tsne.rds")
if (file.exists(rds)) {
  tsne <- readRDS(rds)
} else {
  # Due to the following error:
  # "Error in dr[, seq_len(n_dimred), drop = FALSE]: subscript out of bounds"
  # We use the number of PCs at the next lowest dropoff point which produces no errors.
  tsne <- runTSNE(sce_hvg, use_dimred = "PCA", n_dimred = 18, perplexity = 100, rand_seed = 1)
  saveRDS(tsne, rds)}
```

```{r}
sce_hvg <- tsne
add_df <- data.frame(reducedDim(sce_hvg, "TSNE"))
names(add_df) <- paste0("hvg_denoise_tsne", seq(ncol(add_df)))
colData(sce_hvg) <- cbind(
  colData(sce_hvg), hvg_denoise_tsne1 = add_df$hvg_denoise_tsne1,
  hvg_denoise_tsne2 = add_df$hvg_denoise_tsne2)
colData(sce) <- cbind(
  colData(sce), hvg_denoise_tsne1 = add_df$hvg_denoise_tsne1,
  hvg_denoise_tsne2 = add_df$hvg_denoise_tsne2)
gg_df <- data.frame(gg_df, add_df)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(
    hvg_denoise_tsne1 = median(hvg_denoise_tsne1), hvg_denoise_tsne2 = median(hvg_denoise_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_denoise_tsne1", y = "hvg_denoise_tsne2",
  col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters HVG denoisePCA tSNE")
dim_red_plot(
  data = gg_df, x = "hvg_denoise_tsne1", y = "hvg_denoise_tsne2",
  col = "cell_id_stem", type = "other") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Sample Distribution HVG denoisePCA tSNE")
dim_red_plot(
  data = gg_df, x = "hvg_denoise_tsne1", y = "hvg_denoise_tsne2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("log10(Total Features) HVG denoisePCA tSNE")
```

#### SVD PCA tSNE

Next using the SVD PCs.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "hvg_svd_tsne.rds")
if (file.exists(rds)) {
  tsne <- readRDS(rds)
} else {
  set.seed(1)
  tsne <- Rtsne(svd_pca, pca = FALSE, perplexity = 100)
  saveRDS(tsne, rds)}
```

```{r}
reducedDims(sce_hvg) <- SimpleList(PCA = svd_pca, TSNE = tsne$Y)
add_df <- data.frame(reducedDim(sce_hvg, "TSNE"))
names(add_df) <- paste0("hvg_svd_tsne", seq(ncol(add_df)))
colData(sce_hvg) <- cbind(
  colData(sce_hvg), hvg_svd_tsne1 = add_df$hvg_svd_tsne1, hvg_svd_tsne2 = add_df$hvg_svd_tsne2)
colData(sce) <- cbind(
  colData(sce), hvg_svd_tsne1 = add_df$hvg_svd_tsne1, hvg_svd_tsne2 = add_df$hvg_svd_tsne2)
gg_df <- data.frame(gg_df, add_df)
rm(svd_pca, tsne)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(hvg_svd_tsne1 = median(hvg_svd_tsne1), hvg_svd_tsne2 = median(hvg_svd_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2", col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters HVG SVD tSNE")
dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2", col = "cell_id_stem", type = "other") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Sample Distribution HVG SVD tSNE")
dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("log10(Total Features) HVG SVD tSNE")
```

### Seurat

We start by using Seurat's built-in functions to select the top 1,000 HVGs.

```{r}
# There were issues adding metadata to the Seurat object at the Preliminary Cleaning stage.
# Therefore, for now we opt to convert the SCE object thus far directly to a Seurat one.
seurat <- as.Seurat(sce, counts = "counts", data = NULL)

seurat <- FindVariableFeatures(seurat, selection.method = "vst", nfeatures = 1000)
top_dec <- head(VariableFeatures(seurat), 10)

LabelPoints(plot = VariableFeaturePlot(seurat), points = top_dec, repel = TRUE)
```

#### PCA

```{r}
seurat <- ScaleData(seurat, rownames(seurat))
seurat <- RunPCA(seurat, features = VariableFeatures(object = seurat))
rm(top_dec)

VizDimLoadings(seurat, dims = 1:2, reduction = "pca")
DimPlot(seurat, reduction = "pca", group.by = "habib_cluster_name")
DimHeatmap(seurat, dims = 1:6, cells = 500, balanced = TRUE)
```

As done earlier, we choose the number of PCs for downstream analysis by visually identifying a dropoff in explained variance.
In this case, the value chosen is 16.

```{r}
ElbowPlot(seurat)
```

#### tSNE

```{r}
seurat <- RunTSNE(object = seurat, dims = 1:16, check_duplicates = FALSE)

DimPlot(object = seurat, reduction = "tsne", group.by = "habib_cluster_name", label = TRUE)
DimPlot(object = seurat, reduction = "tsne", group.by = "cell_id_stem")
```
